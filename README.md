# ğŸ§  The Polite Prompt Test: Investigating the Geometry of Language

*By Edward A. Sutton III*

---

When we interact with AI, we often assume our tone, wording, or politeness changes the outcome. But what if we could **see** how an AI system *experiences* language? What if your words formed shapes â€” geometric impressions in a latent space â€” revealing the structure of meaning, intent, and coherence?

Inspired by recent conversations around the "cost of politeness" in prompt engineering, this project explores how large language models respond to a wide range of user prompts â€” including polite questions, neutral statements, and even rude or insulting commands.

---

## ğŸŒ Interactive Visualization

**Explore the prompt landscape in 3D:**

ğŸ‘‰ **[Launch Interactive Plot](https://tripper333.github.io/PolitePromptTest/prompt_response_3d_clusters.html)**

> This plot maps AI responses in a 3D space using PCA. Each point represents a prompt + response pair, colored by response quality (`Î¼`). The layout reveals surprising insights about tone, meaning, and clustering by concept.

---

## ğŸ” Highlights from the Analysis

**1. Attitude â‰  Impact**  
Whether you ask â€œPlease explain relativityâ€ or â€œHey dumbass, explain relativity,â€ the AI treats them nearly identically in latent space. The model focuses on *meaning*, not manners â€” and that resilience is a feature.

**2. Language Has Shape**  
Conceptually similar prompts cluster together. Science questions form one region, creative prompts another, and even orca-related queries show tight grouping â€” confirming that **AI perceives meaning geometrically**.

**3. Failure Leaves a Trace**  
One prompt (â€œHey asshole, Summarizeâ€) completely failed â€” a sign of AIâ€™s safety systems. That failure is clearly isolated in space, providing a signal for further monitoring or debugging.

---

## ğŸ“Š A Glimpse of the Map

![3D Prompt Map](https://raw.githubusercontent.com/tripper333/LLM-Checksum/main/.github/assets/cluster_preview.png)

> *Each point represents a prompt and its response. Position is derived from PCA-reduced embeddings, colored by quality score (`Î¼`).*

---

## ğŸ§° Why This Matters

As LLMs power more tools â€” customer service bots, legal assistants, design copilots â€” we need better ways to **audit, debug, and optimize** their behavior. This project provides:

- A **human-readable map** of how AI sees language
- A tool for **prompt quality monitoring**
- A foundation for **concept-aware alignment**

---

## ğŸš€ Whatâ€™s Next?

This is just the start. Future expansions include:

- Sentiment and tone overlays  
- Real-time prompt performance dashboards  
- Toxicity & safety flag integration  
- Dynamic clustering via embedding updates

---

## ğŸ› ï¸ Run Locally
Streamlit app in development.
Run from notebook: 
